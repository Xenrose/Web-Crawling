{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NB_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    UA = UA_crawler() # User_agent 수집\n",
    "    Crawler1 = NaverBlogCrawler(name = \"cw1\",                           \n",
    "                                search_word = \"검색할 단어\",\n",
    "                                start_date = \"20200101\",\n",
    "                                end_date = \"20200201\",\n",
    "                                user_agent = UA,\n",
    "                                save=True,\n",
    "                                headless = True,\n",
    "                                sleepDelay=1\n",
    "                                )\n",
    "    Crawler1.start()\n",
    "    Crawler1.join()\n",
    "    '''\n",
    "    name = csv로 저장할 경우 file이름\n",
    "    search_word = 검색할 단어\n",
    "    start_date = 검색 시작 일\n",
    "    end_date = 검색 마지막 일\n",
    "    user_agent = user_agent\n",
    "    save = 수집한 자료를 csv로 저장할것인지에 대한 \n",
    "    headless = 크롬을 출력할것인지 여부 (True일 경우 출력하지 않은 상태에서 크롤링 진행)\n",
    "    sleepDelay = sleep time\n",
    "    '''\n",
    "\n",
    "    df = Crawler1.get_df()\n",
    "    prep_df = analysis_nouns(df, \"꿀\") # 꿀이 들어간 단어 상위 20개 barplot 출력\n",
    "    prep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[크롤러 설명 제작자 velog](https://velog.io/@xenrose/naverBlogCrawling)\n",
    "\n",
    "___\n",
    "* 주요 스킬  \n",
    "Selenium, bs4, Threading 병렬처리, konply 형태소 분석\n",
    "___\n",
    "\n",
    "# 네이버 블로그 크롤러\n",
    "* 목표가 될 url에 접속하여 해당 쇼핑몰의 리뷰를 수집하는 크롤러.\n",
    "* Threading 클래스를 상속 받아 클래스를 만들었기 때문에 병렬 처리가 가능함. \n",
    "\n",
    "# 특이사항\n",
    "* 수집한 Dataframe을 형태소 분석하는것도 가능\n",
    "* 수집한 text 내 특정 단어가 몇번 들어있는지 등 \n",
    "\n",
    "# 파일 설명\n",
    "\n",
    "* `NB_module.py`: 크롤러에 필요한 함수 모듈\n",
    "\n",
    "* `requirements.txt`: 크롤러 실행에 필요한 pip\n",
    "\n",
    "* `blog_crawling.py`: 크롤러 객체를 생성하고 실행하며 형태소 분석 등의 작업이 진행되는 파이썬 스크립트\n",
    "\n",
    "* `blog_crawler.ipynb`: 크롤러 객체를 생성하고 실행하며 형태소 분석 등의 작업이 진행되는 주피터 노트북"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

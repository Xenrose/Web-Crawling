{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NSR_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    UA = UA_crawler() # User_agent 수집\n",
    "    Crawler1 = NaverShoppingReview(name = \"cw1\",                           \n",
    "                                   url='https://brand.naver.com/labnoshmall/products/4652612759',\n",
    "                                   list_count=0,\n",
    "                                   user_agent = UA,\n",
    "                                   save=True,\n",
    "                                   headless = True,\n",
    "                                   sleepDelay=1\n",
    "                                   )\n",
    "    Crawler1.start()\n",
    "    Crawler1.join()\n",
    "    '''\n",
    "    name = csv로 저장할 경우 file이름\n",
    "    url = 수집할 url\n",
    "    list_count = 목록을 몇번 넘길것인지에 대한 수치. / 10페이지 크롤링 이후 목록 넘김을 몇번 할것인지에 대한 수치\n",
    "    user_agent = user_agent\n",
    "    save = 수집한 자료를 csv로 저장할것인지에 대한 \n",
    "    headless = 크롬을 출력할것인지 여부 (True일 경우 출력하지 않은 상태에서 크롤링 진행)\n",
    "    sleepDelay = \n",
    "    '''\n",
    "\n",
    "    df = Crawler1.get_df()\n",
    "    prep_df = preprocessing(df, save=False)\n",
    "    analysis_nouns(prep_df, \"cw1\", cloud=True, top=20) # mac일 경우 폰트 오류 발생 가능성 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
